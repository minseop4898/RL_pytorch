{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DQN cartpole-v1 environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(4,512)\n",
    "        self.fc_q = nn.Linear(512,2)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=0.0003)\n",
    "    \n",
    "    def Q(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        q = self.fc_q(x)\n",
    "        return q\n",
    "    \n",
    "    def train(self, loss):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "model = DQN()\n",
    "GAMMA = 0.98\n",
    "EPSILON = 0.1\n",
    "BATCH_SIZE = 32\n",
    "N = 30000 ## reply memory size\n",
    "replay_memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(Q, eps, action_dim):\n",
    "    if random.random() < eps:\n",
    "        action = random.randint(0, action_dim-1)\n",
    "    else:\n",
    "        action = torch.argmax(Q).item()\n",
    "    return action\n",
    "\n",
    "def store_transition(s, a, r, s_prime, done):\n",
    "    if len(replay_memory) == N:\n",
    "        del(replay_memory[0])\n",
    "    replay_memory.append((s, a, r, s_prime, done))\n",
    "    \n",
    "def training():\n",
    "    s_list, r_list, a_list, s_p_list, done_list = [], [], [], [], []\n",
    "    mini_batch = random.sample(replay_memory, BATCH_SIZE)\n",
    "    for sample in mini_batch:\n",
    "        s_list.append(sample[0].unsqueeze(0))\n",
    "        s_p_list.append(sample[3].unsqueeze(0))\n",
    "        r_list.append([sample[2]])\n",
    "        a_list.append([sample[1]])\n",
    "        done_list.append([0]) if sample[-1] else done_list.append([1])\n",
    "    s = torch.cat(s_list, dim=0)\n",
    "    s_p = torch.cat(s_p_list, dim=0)\n",
    "    a = torch.tensor(a_list).reshape(-1,1)\n",
    "    r = torch.tensor(r_list, dtype=torch.float).reshape(-1,1)\n",
    "    done_mask = torch.tensor(done_list, dtype=torch.float).reshape(-1,1)\n",
    "    \n",
    "    cur_Q = model.Q(s)\n",
    "    next_Q = model.Q(s_p)\n",
    "    td_target = r + GAMMA*torch.max(next_Q, dim=1)[0].reshape(-1,1)*done_mask\n",
    "    loss = (td_target.detach() - cur_Q.gather(1,a)).pow(2).mean()\n",
    "    model.train(loss)\n",
    "\n",
    "def test_agent():\n",
    "    reward_sum = 0.0\n",
    "    for ep in range(10):\n",
    "        observation = env.reset()\n",
    "        while True:\n",
    "            state = torch.tensor(observation, dtype=torch.float)\n",
    "            action = torch.argmax(model.Q(state))\n",
    "            observation, reward, done, _ = env.step(action.item())\n",
    "            reward_sum += reward\n",
    "            if done: break\n",
    "    return reward_sum/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 19 , Greedy action reward : 9.400000\n",
      "Episode 39 , Greedy action reward : 9.700000\n",
      "Episode 59 , Greedy action reward : 9.400000\n",
      "Episode 79 , Greedy action reward : 9.100000\n",
      "Episode 99 , Greedy action reward : 9.100000\n",
      "Episode 119 , Greedy action reward : 9.400000\n",
      "Episode 139 , Greedy action reward : 9.500000\n",
      "Episode 159 , Greedy action reward : 10.100000\n",
      "Episode 179 , Greedy action reward : 17.600000\n",
      "Episode 199 , Greedy action reward : 42.300000\n",
      "Episode 219 , Greedy action reward : 22.800000\n",
      "Episode 239 , Greedy action reward : 17.100000\n",
      "Episode 259 , Greedy action reward : 46.300000\n",
      "Episode 279 , Greedy action reward : 49.600000\n",
      "Episode 299 , Greedy action reward : 251.500000\n",
      "Episode 319 , Greedy action reward : 416.900000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-697d0f3abb8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mstore_transition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplay_memory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-afd8d5c3a541>\u001b[0m in \u001b[0;36mtraining\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mtd_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_Q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdone_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtd_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcur_Q\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtest_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-db600702f1b3>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, loss)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reward_list = []\n",
    "\n",
    "for ep in range(2000):\n",
    "    observation = env.reset()\n",
    "    while True:\n",
    "        state = torch.tensor(observation, dtype=torch.float)\n",
    "        action = epsilon_greedy(model.Q(state), EPSILON, 2)\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "        next_state = torch.tensor(observation, dtype=torch.float)\n",
    "        store_transition(state, action, reward, next_state, done)\n",
    "        if len(replay_memory) > 1000:\n",
    "            training()\n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "    if ep % 20 == 19:\n",
    "        test_reward = test_agent()\n",
    "        print('Episode %d'%ep,', Greedy action reward : %f'%(test_reward))\n",
    "        reward_list.append(test_reward)\n",
    "        if test_reward > 470: break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning curve\n",
    "\n",
    "10 game mean score every 20 episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(reward_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ff3c8351f45f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mobservation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(10):\n",
    "    observation = env.reset()\n",
    "    while True:\n",
    "        time.sleep(0.05)\n",
    "        env.render()\n",
    "\n",
    "        state = torch.tensor(observation, dtype=torch.float)\n",
    "        action = torch.argmax(model.Q(state))\n",
    "        observation, reward, done, _ = env.step(action.item())\n",
    "        if done: break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
